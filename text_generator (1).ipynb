{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"/home/prateeksha/Desktop/wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  144424\n",
      "Total Vocab:  45\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print \"Total Characters: \", n_chars\n",
    "print \"Total Vocab: \", n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  144324\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print \"Total Patterns: \", n_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 45)                11565     \n",
      "=================================================================\n",
      "Total params: 275,757\n",
      "Trainable params: 275,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.9756Epoch 00001: loss improved from inf to 2.97553, saving model to weights-improvement-01-2.9755.hdf5\n",
      "144324/144324 [==============================] - 1123s 8ms/step - loss: 2.9755\n",
      "Epoch 2/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.7655Epoch 00002: loss improved from 2.97553 to 2.76548, saving model to weights-improvement-02-2.7655.hdf5\n",
      "144324/144324 [==============================] - 1037s 7ms/step - loss: 2.7655\n",
      "Epoch 3/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.6642Epoch 00003: loss improved from 2.76548 to 2.66408, saving model to weights-improvement-03-2.6641.hdf5\n",
      "144324/144324 [==============================] - 967s 7ms/step - loss: 2.6641\n",
      "Epoch 4/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.5827Epoch 00004: loss improved from 2.66408 to 2.58263, saving model to weights-improvement-04-2.5826.hdf5\n",
      "144324/144324 [==============================] - 969s 7ms/step - loss: 2.5826\n",
      "Epoch 5/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.5217Epoch 00005: loss improved from 2.58263 to 2.52159, saving model to weights-improvement-05-2.5216.hdf5\n",
      "144324/144324 [==============================] - 970s 7ms/step - loss: 2.5216\n",
      "Epoch 6/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.4663Epoch 00006: loss improved from 2.52159 to 2.46627, saving model to weights-improvement-06-2.4663.hdf5\n",
      "144324/144324 [==============================] - 971s 7ms/step - loss: 2.4663\n",
      "Epoch 7/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.4192Epoch 00007: loss improved from 2.46627 to 2.41916, saving model to weights-improvement-07-2.4192.hdf5\n",
      "144324/144324 [==============================] - 972s 7ms/step - loss: 2.4192\n",
      "Epoch 8/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.3796Epoch 00008: loss improved from 2.41916 to 2.37952, saving model to weights-improvement-08-2.3795.hdf5\n",
      "144324/144324 [==============================] - 971s 7ms/step - loss: 2.3795\n",
      "Epoch 9/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.3384Epoch 00009: loss improved from 2.37952 to 2.33835, saving model to weights-improvement-09-2.3383.hdf5\n",
      "144324/144324 [==============================] - 971s 7ms/step - loss: 2.3383\n",
      "Epoch 10/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.2980Epoch 00010: loss improved from 2.33835 to 2.29803, saving model to weights-improvement-10-2.2980.hdf5\n",
      "144324/144324 [==============================] - 973s 7ms/step - loss: 2.2980\n",
      "Epoch 11/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.2570Epoch 00011: loss improved from 2.29803 to 2.25702, saving model to weights-improvement-11-2.2570.hdf5\n",
      "144324/144324 [==============================] - 973s 7ms/step - loss: 2.2570\n",
      "Epoch 12/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.2170Epoch 00012: loss improved from 2.25702 to 2.21711, saving model to weights-improvement-12-2.2171.hdf5\n",
      "144324/144324 [==============================] - 974s 7ms/step - loss: 2.2171\n",
      "Epoch 13/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.1805Epoch 00013: loss improved from 2.21711 to 2.18044, saving model to weights-improvement-13-2.1804.hdf5\n",
      "144324/144324 [==============================] - 976s 7ms/step - loss: 2.1804\n",
      "Epoch 14/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.1444Epoch 00014: loss improved from 2.18044 to 2.14442, saving model to weights-improvement-14-2.1444.hdf5\n",
      "144324/144324 [==============================] - 978s 7ms/step - loss: 2.1444\n",
      "Epoch 15/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.1086Epoch 00015: loss improved from 2.14442 to 2.10863, saving model to weights-improvement-15-2.1086.hdf5\n",
      "144324/144324 [==============================] - 979s 7ms/step - loss: 2.1086\n",
      "Epoch 16/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.0781Epoch 00016: loss improved from 2.10863 to 2.07796, saving model to weights-improvement-16-2.0780.hdf5\n",
      "144324/144324 [==============================] - 979s 7ms/step - loss: 2.0780\n",
      "Epoch 17/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.0442Epoch 00017: loss improved from 2.07796 to 2.04415, saving model to weights-improvement-17-2.0442.hdf5\n",
      "144324/144324 [==============================] - 980s 7ms/step - loss: 2.0442\n",
      "Epoch 18/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.0136Epoch 00018: loss improved from 2.04415 to 2.01359, saving model to weights-improvement-18-2.0136.hdf5\n",
      "144324/144324 [==============================] - 979s 7ms/step - loss: 2.0136\n",
      "Epoch 19/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 1.9840Epoch 00019: loss improved from 2.01359 to 1.98400, saving model to weights-improvement-19-1.9840.hdf5\n",
      "144324/144324 [==============================] - 980s 7ms/step - loss: 1.9840\n",
      "Epoch 20/20\n",
      "144256/144324 [============================>.] - ETA: 0s - loss: 2.0259Epoch 00020: loss did not improve\n",
      "144324/144324 [==============================] - 979s 7ms/step - loss: 2.0260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a27d0b9d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename =  'weights-improvement-19-1.9840.hdf5'\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  said the caterpillar.\n",
      "\n",
      "this was not an encouraging opening for a conversation. alice replied,\n",
      "rathe \"\n",
      "r alo the woide thet she was aoling to tienting to tie thete was soenting and the harter whet she was not th theh  the was allie  to toe to her an tnee as the could. \n",
      "'the doessseen toue if ind toen i se got in,' said the monk turtle \n",
      "iitevery ao in spoke. \n",
      "'ieve you touldn'' said the manch hare.\n",
      "\n",
      "'whet wer the woute gane to tee touting,' said the manch hare.\n",
      "\n",
      "'whet wer the woute gane to tee touting,' said the manch hare.\n",
      "\n",
      "'whet wer the woute gane to tee touting,' said the manch hare.\n",
      "\n",
      "'whet wer the woute gane to tee touting,' said the manch hare.\n",
      "\n",
      "'whet wer the woute gane to tee touting,' said the manch hare.\n",
      "\n",
      "'whet wer the woute gane to tee touting,' said the manch hare.\n",
      "\n",
      "'whet wer the woute gane to tee touting,' said the manch hare.\n",
      "\n",
      "'whet wer the woute gane to tee touting,' said the manch hare.\n",
      "\n",
      "'whet wer the woute gane to tee touting,' said the manch hare.\n",
      "\n",
      "'whet wer the woute gane to tee touting,' said the manch hare.\n",
      "\n",
      "'whet wer the woute gane to tee touting,' said the manch hare\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print \"Seed:\"\n",
    "print \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\"\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print \"\\nDone.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# larger LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences =True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "144320/144324 [============================>.] - ETA: 0s - loss: 2.7899Epoch 00001: loss improved from inf to 2.78988, saving model to weights-improvement-01-2.7899-bigger.hdf5\n",
      "144324/144324 [==============================] - 3419s 24ms/step - loss: 2.7899\n",
      "Epoch 2/5\n",
      "144320/144324 [============================>.] - ETA: 0s - loss: 2.4284Epoch 00002: loss improved from 2.78988 to 2.42844, saving model to weights-improvement-02-2.4284-bigger.hdf5\n",
      "144324/144324 [==============================] - 3181s 22ms/step - loss: 2.4284\n",
      "Epoch 3/5\n",
      "144320/144324 [============================>.] - ETA: 0s - loss: 2.2129Epoch 00003: loss improved from 2.42844 to 2.21296, saving model to weights-improvement-03-2.2130-bigger.hdf5\n",
      "144324/144324 [==============================] - 3176s 22ms/step - loss: 2.2130\n",
      "Epoch 4/5\n",
      "144320/144324 [============================>.] - ETA: 0s - loss: 2.0752Epoch 00004: loss improved from 2.21296 to 2.07519, saving model to weights-improvement-04-2.0752-bigger.hdf5\n",
      "144324/144324 [==============================] - 3177s 22ms/step - loss: 2.0752\n",
      "Epoch 5/5\n",
      "144320/144324 [============================>.] - ETA: 0s - loss: 1.9783Epoch 00005: loss improved from 2.07519 to 1.97832, saving model to weights-improvement-05-1.9783-bigger.hdf5\n",
      "144324/144324 [==============================] - 3177s 22ms/step - loss: 1.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc29e3e46d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose =1, save_best_only = True, mode ='min' )\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X, y, epochs=5, batch_size=64, callbacks= callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename =  'weights-improvement-05-1.9783-bigger.hdf5'\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  then turned to the dormouse, and\n",
      "repeated her question. 'why did they live at the bottom of a well? \"\n",
      "'\n",
      "\n",
      "'i mnow the said the mittle saie to be a little shat the was a little shme the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little was the was a little wa\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print \"Seed:\"\n",
    "print \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\"\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print \"\\nDone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
